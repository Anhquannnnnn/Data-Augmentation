{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "812544cd-89d5-419b-8ca4-8eab260ae14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cb2e418-e540-4f5a-bfac-a8c01e762aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU Memory: 6.44 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X Axis</th>\n",
       "      <th>Y Axis</th>\n",
       "      <th>Z Axis</th>\n",
       "      <th>speed</th>\n",
       "      <th>std speed</th>\n",
       "      <th>flashes</th>\n",
       "      <th>height</th>\n",
       "      <th>flash time</th>\n",
       "      <th>number of flashes</th>\n",
       "      <th>time</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7,732100079</td>\n",
       "      <td>21,27411752</td>\n",
       "      <td>0,836535186</td>\n",
       "      <td>0,893909107</td>\n",
       "      <td>37,5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19,40939338</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8,93297619</td>\n",
       "      <td>24,14391967</td>\n",
       "      <td>0,997566682</td>\n",
       "      <td>0,981108211</td>\n",
       "      <td>41,78899083</td>\n",
       "      <td>327.0</td>\n",
       "      <td>19,99695986</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1,4209136</td>\n",
       "      <td>25,14055993</td>\n",
       "      <td>0,992084814</td>\n",
       "      <td>0,964873731</td>\n",
       "      <td>42,41145833</td>\n",
       "      <td>576.0</td>\n",
       "      <td>20,02562567</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-7,024316029</td>\n",
       "      <td>23,48523655</td>\n",
       "      <td>0,989346321</td>\n",
       "      <td>0,951449147</td>\n",
       "      <td>44,36641221</td>\n",
       "      <td>655.0</td>\n",
       "      <td>19,95115159</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-14,05511477</td>\n",
       "      <td>25,16917632</td>\n",
       "      <td>0,987477067</td>\n",
       "      <td>0,930151443</td>\n",
       "      <td>46,10802139</td>\n",
       "      <td>935.0</td>\n",
       "      <td>19,96782501</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X Axis  Y Axis  Z Axis         speed    std speed      flashes  \\\n",
       "0       0       0       0   7,732100079  21,27411752  0,836535186   \n",
       "1       0       1       0    8,93297619  24,14391967  0,997566682   \n",
       "2       0       2       0     1,4209136  25,14055993  0,992084814   \n",
       "3       0       3       0  -7,024316029  23,48523655  0,989346321   \n",
       "4       0       4       0  -14,05511477  25,16917632  0,987477067   \n",
       "\n",
       "        height   flash time  number of flashes         time direction  \n",
       "0  0,893909107         37,5               12.0  19,40939338         V  \n",
       "1  0,981108211  41,78899083              327.0  19,99695986         U  \n",
       "2  0,964873731  42,41145833              576.0  20,02562567         U  \n",
       "3  0,951449147  44,36641221              655.0  19,95115159         U  \n",
       "4  0,930151443  46,10802139              935.0  19,96782501         U  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "data = pd.read_csv('data/Physical experiments.csv',sep= ';')\n",
    "num = data.select_dtypes(np.number)\n",
    "cat= data.select_dtypes(exclude=np.number)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6221b-105c-4aa1-8186-85479aec8349",
   "metadata": {},
   "source": [
    "## CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecf2465b-2f24-4afb-b3f4-93c742cd46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data,dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "class Conditioner(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x)) \n",
    "\n",
    "class CTGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim + output_dim, hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()  \n",
    "        )\n",
    "        self.conditioner = Conditioner(output_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, z, c):\n",
    "        condition = self.conditioner(c)\n",
    "        inputs = torch.cat([z, condition], dim=1) \n",
    "        x = self.net(inputs)\n",
    "        return x\n",
    "\n",
    "class CTGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, hidden_dim), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        inputs = torch.cat([x, c], dim=1)  \n",
    "        return self.net(inputs)\n",
    "\n",
    "class CTGAN:\n",
    "    def __init__(self, input_dim, latent_dim=100, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "        self.generator = CTGANGenerator(latent_dim, input_dim).to(device)\n",
    "        self.discriminator = CTGANDiscriminator(input_dim).to(device)\n",
    "        self.g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "        \n",
    "    def train_step(self, real_data, conditions):\n",
    "        batch_size = real_data.shape[0]\n",
    "        real_data = real_data.to(self.device)\n",
    "        conditions = conditions.to(self.device)\n",
    "        \n",
    "\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "        fake_data = self.generator(z, conditions)\n",
    "        \n",
    "        real_pred = self.discriminator(real_data, conditions)\n",
    "        fake_pred = self.discriminator(fake_data.detach(), conditions)\n",
    "        \n",
    "        d_loss_real = -torch.mean(torch.log(real_pred + 1e-8))\n",
    "        d_loss_fake = -torch.mean(torch.log(1 - fake_pred + 1e-8))\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "        fake_data = self.generator(z, conditions)\n",
    "        fake_pred = self.discriminator(fake_data, conditions)\n",
    "        \n",
    "        g_loss = -torch.mean(torch.log(fake_pred + 1e-8))\n",
    "        \n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return d_loss.item(), g_loss.item()\n",
    "\n",
    "    def train(self, data, conditions, epochs=200, batch_size=500):\n",
    "        data = torch.FloatTensor(data)\n",
    "        conditions = torch.FloatTensor(conditions)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            d_losses = []\n",
    "            g_losses = []\n",
    "            \n",
    "            idx = torch.randperm(len(data))\n",
    "            data = data[idx]\n",
    "            conditions = conditions[idx]\n",
    "            \n",
    "            for i in range(0, len(data), batch_size):\n",
    "                batch_data = data[i:i+batch_size]\n",
    "                batch_conditions = conditions[i:i+batch_size]\n",
    "                d_loss, g_loss = self.train_step(batch_data, batch_conditions)\n",
    "                d_losses.append(d_loss)\n",
    "                g_losses.append(g_loss)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}: D_loss={np.mean(d_losses):.4f}, G_loss={np.mean(g_losses):.4f}')\n",
    "    \n",
    "    def generate(self, num_samples, conditions):\n",
    "        self.generator.eval()\n",
    "        conditions = torch.FloatTensor(conditions).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_samples, self.latent_dim, device=self.device)\n",
    "            samples = self.generator(z, conditions)\n",
    "        return samples.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf3e8b-39e0-4455-8b7a-be7ff8d360a8",
   "metadata": {},
   "source": [
    "## Entrainement et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc0813a-74d6-441e-8aa1-b5e1e65961f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ctgan(data, conditions=None, test_size=0.2, epochs=200, batch_size=500):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "    \n",
    "    if conditions is None:\n",
    "        conditions = data  \n",
    "    train_conditions, test_conditions = train_test_split(conditions, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Initialize CTGAN\n",
    "    input_dim = data.shape[1]\n",
    "    ctgan = CTGAN(input_dim)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'd_losses': [],\n",
    "        'g_losses': []\n",
    "    }\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        \n",
    "        # Shuffle data\n",
    "        idx = np.random.permutation(len(train_data))\n",
    "        epoch_data = train_data[idx]\n",
    "        epoch_conditions = train_conditions[idx]\n",
    "        \n",
    "        for i in range(0, len(epoch_data), batch_size):\n",
    "            batch_data = torch.FloatTensor(epoch_data[i:i+batch_size])\n",
    "            batch_conditions = torch.FloatTensor(epoch_conditions[i:i+batch_size])\n",
    "            \n",
    "            d_loss, g_loss = ctgan.train_step(batch_data, batch_conditions)\n",
    "            d_losses.append(d_loss)\n",
    "            g_losses.append(g_loss)\n",
    "        \n",
    "        # Record losses\n",
    "        history['d_losses'].append(np.mean(d_losses))\n",
    "        history['g_losses'].append(np.mean(g_losses))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: D_loss={np.mean(d_losses):.4f}, G_loss={np.mean(g_losses):.4f}')\n",
    "    \n",
    "    return ctgan, history, test_data, test_conditions\n",
    "\n",
    "def evaluate_generated_data(real_data, generated_data, continuous_columns, categorical_columns=None):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    ks_tests = {}\n",
    "    for idx, col in enumerate(continuous_columns):\n",
    "        statistic, pvalue = ks_2samp(real_data[:, idx], generated_data[:, idx])\n",
    "        ks_tests[col] = {'statistic': statistic, 'pvalue': pvalue}\n",
    "    \n",
    "    results['ks_tests'] = ks_tests\n",
    "    \n",
    "    # Calculate means and stds\n",
    "    real_means = np.mean(real_data, axis=0)\n",
    "    real_stds = np.std(real_data, axis=0)\n",
    "    gen_means = np.mean(generated_data, axis=0)\n",
    "    gen_stds = np.std(generated_data, axis=0)\n",
    "    \n",
    "    results['statistics'] = {\n",
    "        'real_means': real_means,\n",
    "        'real_stds': real_stds,\n",
    "        'gen_means': gen_means,\n",
    "        'gen_stds': gen_stds\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['d_losses'], label='Discriminator Loss')\n",
    "    plt.plot(history['g_losses'], label='Generator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_distributions(real_data, generated_data, continuous_columns, num_cols=3):\n",
    "    \"\"\"\n",
    "    Plot distributions of real and generated data\n",
    "    \"\"\"\n",
    "    num_features = len(continuous_columns)\n",
    "    num_rows = (num_features + num_cols - 1) // num_cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * num_rows))\n",
    "    \n",
    "    for idx, col in enumerate(continuous_columns):\n",
    "        plt.subplot(num_rows, num_cols, idx + 1)\n",
    "        sns.kdeplot(real_data[:, idx], label='Real', color='blue')\n",
    "        sns.kdeplot(generated_data[:, idx], label='Generated', color='red')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2900d914-5a00-4486-9a89-83d5c5141c32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([ 78,  16,  65, 114,  76,  19, 122,  24,  66, 152,\\n       ...\\n        87,  74, 121, 178,  20,  71, 106,  14,  92, 102],\\n      dtype='int32', length=179)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      8\u001b[0m continuous_columns \u001b[38;5;241m=\u001b[39m num\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m---> 11\u001b[0m ctgan_model, history, test_data, test_conditions \u001b[38;5;241m=\u001b[39m train_ctgan(\n\u001b[0;32m     12\u001b[0m         num, \n\u001b[0;32m     13\u001b[0m         conditions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m     15\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m n_synthetic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data)\n",
      "Cell \u001b[1;32mIn[36], line 28\u001b[0m, in \u001b[0;36mtrain_ctgan\u001b[1;34m(data, conditions, test_size, epochs, batch_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Shuffle data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(train_data))\n\u001b[1;32m---> 28\u001b[0m epoch_data \u001b[38;5;241m=\u001b[39m train_data[idx]\n\u001b[0;32m     29\u001b[0m epoch_conditions \u001b[38;5;241m=\u001b[39m train_conditions[idx]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(epoch_data), batch_size):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torchenv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torchenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torchenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([ 78,  16,  65, 114,  76,  19, 122,  24,  66, 152,\\n       ...\\n        87,  74, 121, 178,  20,  71, 106,  14,  92, 102],\\n      dtype='int32', length=179)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "    \n",
    "\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "\n",
    "continuous_columns = num.columns\n",
    "    \n",
    "\n",
    "ctgan_model, history, test_data, test_conditions = train_ctgan(\n",
    "        num, \n",
    "        conditions=None,\n",
    "        epochs=200,\n",
    "        batch_size=100\n",
    "    )\n",
    "    \n",
    "    # Generate synthetic data\n",
    "n_synthetic = len(test_data)\n",
    "synthetic_data = ctgan_model.generate(n_synthetic, test_conditions)\n",
    "    \n",
    "    # Evaluate results\n",
    "evaluation = evaluate_generated_data(test_data, synthetic_data, continuous_columns)\n",
    "    \n",
    "    # Plot results\n",
    "plot_training_history(history)\n",
    "plot_distributions(test_data, synthetic_data, continuous_columns)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "print(\"\\nKolmogorov-Smirnov test results:\")\n",
    "for col, results in evaluation['ks_tests'].items():\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Statistic: {results['statistic']:.4f}\")\n",
    "    print(f\"  P-value: {results['pvalue']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch Environment",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
